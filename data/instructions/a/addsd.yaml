%YAML 1.2
---
title: Add Scalar Double-Precision Floating-Point Value
opcode:
  - opcode: F2 0F 58 /r
    mnemonic: ADDSD \i{xmm1}, \i{xmm2/m64}
    encoding: LEGACY
    validity:
      16: invalid
      32: valid
      64: valid
    cpuid: SSE2
    description: >-
      Adds a single double-precision floating-point value from \i{xmm2/m64} and \i{xmm1}.
      Stores the result in \i{xmm1}.
  - opcode: VEX.LIG.F2.0F.WIG 58 /r
    mnemonic: VADDSD \i{xmm1}, \i{xmm2}, \i{xmm3/m64}
    encoding: VEX
    validity:
      16: invalid
      32: valid
      64: valid
    cpuid: AVX
    description: >-
      Adds a single double-precision floating-point value from \i{xmm3/m64} and \i{xmm2}.
      Stores the result in \i{xmm1}.
  - opcode: EVEX.LIG.F2.0F.W1 58 /r
    mnemonic: VADDSD \i{xmm1} {k1}{z}, \i{xmm2}, \i{xmm3/m64} {er}
    encoding: EVEX
    validity:
      16: invalid
      32: valid
      64: valid
    cpuid: AVX512F
    description: >-
      Adds a single double-precision floating-point value from \i{xmm3/m64} and \i{xmm2}.
      Stores the result in \i{xmm1} using writemask \i{k1}.
encoding:
  operands: 3
  hasTuple: true
  encodings:
    LEGACY:
      - N/A
      - ModRM.reg[rw]
      - ModRM.r/m[r]
      - ""
    VEX:
      - N/A
      - ModRM.reg[w]
      - VEX.vvvv[r]
      - ModRM.r/m[r]
    EVEX:
      - Tuple1 Scalar
      - ModRM.reg[w]
      - EVEX.vvvv[r]
      - ModRM.r/m[r]
bitEncoding:
  list:
    - form: xmmreg3(2) into xmmreg3(1)
      bits:
        - \bits{F2}
        - \bits{0F}
        - \bits{58}
        - \bits{11 xmmreg3(1) xmmreg3(2)}
    - form: memory into xmmreg3
      bits:
        - \bits{F2}
        - \bits{0F}
        - \bits{58}
        - \bits{mod xmmreg3 r/m}
description: >-
  The \c{(V)ADDSD} instruction adds a single double-precision floating-point from the first source operand and the second source operand.
  The result is stored in in the destination operand.

  The legacy SSE version (\c{ADDSD}) works on the lowest 64 bits and leaves all others unchanged.

  The AVX versions (\c{VADDSD}) work on the lowest 64 bits, but also copy the next 64 bits from the first source operand to the destination.
  Afterwards, all unchanged bits in the destination are zeroed.

  Although this instruction works with \c{(E)VEX.LIG}, Intel recommends that assemblers set \c{(E)VEX.L} to 0.
  Encoding with \c{(E)VEX.L} being 1 may not be allowed in the future.
operation: |-
  public void ADDSD(SimdF64 dest, SimdF64 src)
  {
    dest[0] += src[0];
    // dest[1..Simd.MAX] (unchanged)
  }

  public void VADDSD_Vex(SimdF64 dest, SimdF64 src1, SimdF64 src2)
  {
    dest[0] = src1[0] + src2[0];
    dest[1] = src1[1];
    dest[2..Simd.MAX] = 0;
  }

  public void VADDSD_EvexMemory(SimdF64 dest, SimdF64 src1, SimdF64 src2, KMask k)
  {
    if (k[0])
      dest[0] = src1[0] + src2[0];
    else if (EVEX.z)
      dest[0] = 0;
    dest[1] = src1[1];
    dest[2..Simd.MAX] = 0;
  }

  public void VADDSD_EvexRegister(SimdF64 dest, SimdF64 src1, SimdF64 src2, KMask k)
  {
    if (EVEX.b)
      SetRoundingForThisInstruction(EVEX.rc);
    else
      SetRoundingForThisInstruction(MXCSR.rc);

    if (k[0])
      dest[0] = src1[0] + src2[0];
    else if (EVEX.z)
      dest[0] = 0;
    dest[1] = src1[1];
    dest[2..Simd.MAX] = 0;
  }
intrinsics: |-
  __m128d _mm_add_sd(__m128d a, __m128d b)
  __m128d _mm_add_round_sd(__m128d a, __m128d b, int32_t rounding)
  __m128d _mm_mask_add_sd(__m128d s, __mmask8 k, __m128d a, __m128d b)
  __m128d _mm_mask_add_round_sd(__m128d s, __mmask8 k, __m128d a, __m128d b, int32_t rounding)
  __m128d _mm_maskz_add_sd(__mmask8 k, __m128d a, __m128d b)
  __m128d _mm_maskz_add_round_sd (__mmask8 k, __m128d a, __m128d b, int32_t rounding)
exceptions:
  floating: Overflow, Underflow, Invalid, Precision, Denormal
  other:
    - "VEX encoded form: see Exceptions Type 2."
    - "EVEX encoded form: see Exceptions Type E2."
