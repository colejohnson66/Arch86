%YAML 1.2
---
title: Add Scalar Single-Precision Floating-Point Value
opcode:
  - opcode: F3 0F 58 /r
    mnemonic: ADDSS \i{xmm1}, \i{xmm2/m32}
    encoding: LEGACY
    validity:
      16: invalid
      32: valid
      64: valid
    cpuid: SSE2
    description: >-
      Adds a single single-precision floating-point value from \i{xmm2/m32} and \i{xmm1}.
      Stores the result in \i{xmm1}.
  - opcode: VEX.LIG.F3.0F.WIG 58 /r
    mnemonic: VADDSS \i{xmm1}, \i{xmm2}, \i{xmm3/m32}
    encoding: VEX
    validity:
      16: invalid
      32: valid
      64: valid
    cpuid: AVX
    description: >-
      Adds a single single-precision floating-point value from \i{xmm3/m32} and \i{xmm2}.
      Stores the result in \i{xmm1}.
  - opcode: EVEX.LIG.F3.0F.W0 58 /r
    mnemonic: VADDSS \i{xmm1} {k1}{z}, \i{xmm2}, \i{xmm3/m32} {er}
    encoding: EVEX
    validity:
      16: invalid
      32: valid
      64: valid
    cpuid: AVX512F
    description: >-
      Adds a single single-precision floating-point value from \i{xmm3/m32} and \i{xmm2}.
      Stores the result in \i{xmm1} using writemask \i{k1}.
encoding:
  operands: 3
  hasTuple: true
  encodings:
    LEGACY:
      - N/A
      - ModRM.reg[rw]
      - ModRM.r/m[r]
      - ""
    VEX:
      - N/A
      - ModRM.reg[w]
      - VEX.vvvv[r]
      - ModRM.r/m[r]
    EVEX:
      - Tuple1 Scalar
      - ModRM.reg[w]
      - EVEX.vvvv[r]
      - ModRM.r/m[r]
description: >-
  The \c{(V)ADDSS} instruction adds a single single-precision floating-point from the first source operand and the second source operand.
  The result is stored in in the destination operand.

  The legacy SSE version (\c{ADDSS}) works on the lowest 32 bits and leaves all others unchanged.

  The AVX versions (\c{VADDSS}) work on the lowest 32 bits, but also copy the next 96 bits from the first source operand to the destination.
  Afterwards, all unchanged bits in the destination are zeroed.

  \canned{vexLShouldBe0}
operation: |-
  public void ADDSS(SimdF32 dest, SimdF32 src)
  {
    dest[0] += src[0];
    // dest[1..SimdF32.MAX] (unchanged)
  }

  public void VADDSS_Vex(SimdF32 dest, SimdF32 src1, SimdF32 src2)
  {
    dest[0] = src1[0] + src2[0];
    dest[1] = src1[1];
    dest[2] = src1[2];
    dest[3] = src1[3];
    dest[4..SimdF32.MAX] = 0;
  }

  public void VADDSS_EvexMemory(SimdF32 dest, SimdF32 src1, SimdF32 src2, KMask k)
  {
    if (k[0])
      dest[0] = src1[0] + src2[0];
    else if (EVEX.z)
      dest[0] = 0;
    dest[1] = src1[1];
    dest[2] = src1[2];
    dest[3] = src1[3];
    dest[4..SimdF32.MAX] = 0;
  }

  public void VADDSS_EvexRegister(SimdF32 dest, SimdF32 src1, SimdF32 src2, KMask k)
  {
    if (EVEX.b)
      SetRoundingForThisInstruction(EVEX.rc);
    else
      SetRoundingForThisInstruction(MXCSR.rc);

    if (k[0])
      dest[0] = src1[0] + src2[0];
    else if (EVEX.z)
      dest[0] = 0;
    dest[1] = src1[1];
    dest[2] = src1[2];
    dest[3] = src1[3];
    dest[4..SimdF32.MAX] = 0;
  }
intrinsics: |-
  __m128 _mm_add_ss(__m128 a, __m128 b)
  __m128 _mm_add_round_ss(__m128 a, __m128 b, int32_t rounding)
  __m128 _mm_mask_add_ss(__m128 s, __mmask8 k, __m128 a, __m128 b)
  __m128 _mm_mask_add_round_ss(__m128 s, __mmask8 k, __m128 a, __m128 b, int32_t rounding)
  __m128 _mm_maskz_add_ss(__mmask8 k, __m128 a, __m128 b)
  __m128 _mm_maskz_add_round_ss(__mmask8 k, __m128 a, __m128 b, int32_t rounding)
exceptions:
  floating: Overflow, Underflow, Invalid, Precision, Denormal
  other:
    - \exceptionVex{2}
    - \exceptionEvex{E2}
